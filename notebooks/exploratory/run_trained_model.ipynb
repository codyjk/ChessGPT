{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3f1c99-2b7d-4f45-945c-6ec7607da5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from chess_model import fit_tokenizer, ChessTransformer\n",
    "\n",
    "TRAINING_DATA_FILE = \"out/training-data.csv\"\n",
    "MODEL_OUTPUT_FILE = \"out/chess_transformer_model.pth\"\n",
    "\n",
    "# Change these to whatever the model was trained with!\n",
    "# These values match the defaults in ChessTransformer:\n",
    "# MAX_LEN = 10\n",
    "# N_EMBD = 256\n",
    "# N_LAYER = 4\n",
    "# N_HEAD = 4\n",
    "MAX_LEN = 5\n",
    "N_EMBD = 64\n",
    "N_LAYER = 1\n",
    "N_HEAD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b430031-c183-4e0a-b9cb-e66d35e00e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = fit_tokenizer(f\"../../{TRAINING_DATA_FILE}\")\n",
    "print(f'Tokenizer initialized with vocab_size={tokenizer.vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a4ffb-225f-46fb-af76-f7bf81e78db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ChessTransformer(vocab_size=tokenizer.vocab_size, n_positions=MAX_LEN, n_embd=N_EMBD, n_layer=N_LAYER, n_head=N_HEAD)\n",
    "model.load_state_dict(torch.load(f\"../../{MODEL_OUTPUT_FILE}\"))\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Loaded model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ade1b1-c715-42a3-9931-530a337edfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chess_model import ChessDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = ChessDataset(f\"../../{TRAINING_DATA_FILE}\", tokenizer, max_length=MAX_LEN)\n",
    "dataloader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54725859-0f6d-4ed5-892c-5e7fda88405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sample in enumerate(dataloader):\n",
    "    if i >5:\n",
    "        break\n",
    "    moves = sample['input_ids'][0].tolist()\n",
    "    next_move = sample['labels'].tolist()\n",
    "    print(f'Moves: {tokenizer.decode(moves)}')\n",
    "    print(f'Next:  {tokenizer.decode(next_move)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3380f610-8082-4b57-8c4b-88075248dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def preprocess_input(move_sequence, tokenizer, max_length=MAX_LEN):\n",
    "    # Tokenize the input sequence\n",
    "    input_ids = tokenizer.encode(move_sequence)\n",
    "    \n",
    "    # Truncate or pad the sequence to max_length\n",
    "    if len(input_ids) > max_length:\n",
    "        input_ids = input_ids[-max_length:]\n",
    "    else:\n",
    "        input_ids = [0] * (max_length - len(input_ids)) + input_ids\n",
    "\n",
    "    decoded = tokenizer.decode(input_ids)\n",
    "    print(f'Move sequence: {move_sequence}')\n",
    "    print(f'Encoded:       {input_ids}')\n",
    "    print(f'Decoded:       {decoded}')\n",
    "    \n",
    "    return torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "\n",
    "def predict_next_move(model, tokenizer, move_sequence, device, temperature=1.0, top_k=5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    # Preprocess the input\n",
    "    input_ids = preprocess_input(move_sequence, tokenizer).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        move_logits = model(input_ids)\n",
    "    \n",
    "    # Apply temperature to logits\n",
    "    move_logits = move_logits / temperature\n",
    "    \n",
    "    # Get probabilities\n",
    "    move_probs = F.softmax(move_logits, dim=-1)\n",
    "\n",
    "    # Zero out the probability of the last move in the sequence\n",
    "    last_move_id = tokenizer.encode([move_sequence[-1]])[0]\n",
    "    move_probs[0, last_move_id] = 0\n",
    "    \n",
    "    # Normalize probabilities after zeroing out the last move\n",
    "    move_probs = move_probs / move_probs.sum()\n",
    "    \n",
    "    # Get top-k moves\n",
    "    top_k_probs, top_k_indices = torch.topk(move_probs, top_k)\n",
    "    \n",
    "    # Sample from top-k moves\n",
    "    sampled_index = torch.multinomial(top_k_probs.squeeze(), 1).item()\n",
    "    predicted_move_id = top_k_indices.squeeze()[sampled_index].item()\n",
    "    predicted_move = tokenizer.decode([predicted_move_id])\n",
    "\n",
    "    return predicted_move, move_probs\n",
    "\n",
    "def interpret_prediction(predicted_move, move_probs, tokenizer):\n",
    "    print(f\"Predicted next move: {predicted_move}\")\n",
    "    \n",
    "    # Debugging information\n",
    "    print(\"\\nDebugging Information:\")\n",
    "    print(f\"Vocabulary size: {len(tokenizer.move_to_id)}\")\n",
    "    print(\"Top 5 predicted moves:\")\n",
    "    top_moves = torch.topk(move_probs.squeeze(), 5)\n",
    "    for i, (prob, idx) in enumerate(zip(top_moves.values, top_moves.indices)):\n",
    "        move = tokenizer.decode([idx.item()])\n",
    "        print(f\"  {i+1}. {move} (probability: {prob.item():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79903883-763e-4731-adbe-3d675aaf5099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "move_sequence = ['e4', 'e5']\n",
    "\n",
    "predicted_move, move_probs = predict_next_move(model, tokenizer, move_sequence, device, temperature=0.8, top_k=5)\n",
    "interpret_prediction(predicted_move, move_probs, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02987bf9-fd8c-4576-9e80-c939040c5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in enumerate(tokenizer.move_to_id):\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c88779-c1bc-4baf-8fdb-d82b76e8a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model vocab size: {model.config.vocab_size}\")\n",
    "print(f\"Tokenizer vocab size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e9d66-2256-4576-8e52-6aadd0f6ec8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
