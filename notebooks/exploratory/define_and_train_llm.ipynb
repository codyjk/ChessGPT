{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6550d298",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch\n",
    "%pip install transformers\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed846484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from typing import Iterator, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_game(game: str) -> Iterator[Tuple[str, str, str, str]]:\n",
    "    moves = game.split()\n",
    "    outcome = moves[-1]\n",
    "    moves = moves[:-1]  # Remove the outcome from the move list\n",
    "    \n",
    "    for i in range(len(moves)):\n",
    "        context = \" \".join(moves[:i])\n",
    "        next_move = moves[i]\n",
    "        is_checkmate = \"1\" if next_move.endswith(\"#\") else \"0\"\n",
    "        \n",
    "        # For the last move, we know the outcome\n",
    "        if i == len(moves) - 1:\n",
    "            yield context, next_move, is_checkmate, outcome\n",
    "        else:\n",
    "            yield context, next_move, is_checkmate, \"\"\n",
    "\n",
    "def prepare_training_data(input_file: str, train_file: str, val_file: str, max_context_length: int = 50, val_split: float = 0.1):\n",
    "    with open(train_file, 'w', newline='') as train_outfile, open(val_file, 'w', newline='') as val_outfile:\n",
    "        train_writer = csv.writer(train_outfile)\n",
    "        val_writer = csv.writer(val_outfile)\n",
    "        \n",
    "        headers = ['context', 'next_move', 'is_checkmate', 'outcome']\n",
    "        train_writer.writerow(headers)\n",
    "        val_writer.writerow(headers)\n",
    "        \n",
    "        # Count total lines for progress bar\n",
    "        total_lines = sum(1 for _ in open(input_file, 'r'))\n",
    "        \n",
    "        with open(input_file, 'r') as infile:\n",
    "            for line in tqdm(infile, total=total_lines, desc=\"Processing games\"):\n",
    "                game = line.strip()\n",
    "                for context, next_move, is_checkmate, outcome in process_game(game):\n",
    "                    # Limit context to last `max_context_length` moves\n",
    "                    context_moves = context.split()[-max_context_length:]\n",
    "                    limited_context = \" \".join(context_moves)\n",
    "                    \n",
    "                    # Decide whether to write to train or val file\n",
    "                    if random.random() < val_split:\n",
    "                        val_writer.writerow([limited_context, next_move, is_checkmate, outcome])\n",
    "                    else:\n",
    "                        train_writer.writerow([limited_context, next_move, is_checkmate, outcome])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_training_data(\"out/grandmaster.txt\", \"out/training-data.csv\", \"out/validation-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbd0ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import GPT2Config, GPT2Model\n",
    "\n",
    "class ChessTransformer(nn.Module):\n",
    "    # The defaults here are a relatively small and easy-to-train model\n",
    "    def __init__(self, vocab_size, n_positions=50, n_embd=128, n_layer=2, n_head=2):\n",
    "        super(ChessTransformer, self).__init__()\n",
    "        \n",
    "        self.config = GPT2Config(\n",
    "            vocab_size=vocab_size,\n",
    "            n_positions=n_positions,\n",
    "            n_embd=n_embd,\n",
    "            n_layer=n_layer,\n",
    "            n_head=n_head\n",
    "        )\n",
    "        \n",
    "        self.transformer = GPT2Model(self.config)\n",
    "        self.move_head = nn.Linear(n_embd, vocab_size)\n",
    "        self.checkmate_head = nn.Linear(n_embd, 1)\n",
    "        self.outcome_head = nn.Linear(n_embd, 3)  # Win, Loss, Draw\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.transformer(input_ids, attention_mask=attention_mask)\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        prediction_hidden_state = hidden_states[:, -1, :]\n",
    "        \n",
    "        move_logits = self.move_head(prediction_hidden_state)\n",
    "        checkmate_logits = self.checkmate_head(prediction_hidden_state)\n",
    "        outcome_logits = self.outcome_head(prediction_hidden_state)\n",
    "        \n",
    "        return move_logits, checkmate_logits, outcome_logits\n",
    "        \n",
    "class ChessTokenizer:\n",
    "    def __init__(self):\n",
    "        self.move_to_id = {\"[PAD]\": 0, \"[UNK]\": 1}\n",
    "        self.id_to_move = {0: \"[PAD]\", 1: \"[UNK]\"}\n",
    "        self.vocab_size = 2  # Start with PAD and UNK tokens\n",
    "\n",
    "    def fit(self, moves):\n",
    "        for move in moves:\n",
    "            if move not in self.move_to_id:\n",
    "                self.move_to_id[move] = self.vocab_size\n",
    "                self.id_to_move[self.vocab_size] = move\n",
    "                self.vocab_size += 1\n",
    "\n",
    "    def encode(self, moves):\n",
    "        return [self.move_to_id.get(move, self.move_to_id[\"[UNK]\"]) for move in moves]\n",
    "\n",
    "    def decode(self, ids):\n",
    "        return [self.id_to_move.get(id, \"[UNK]\") for id in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6272a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import csv\n",
    "import mmap\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=50):\n",
    "        self.csv_file = csv_file\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.line_offsets = []\n",
    "\n",
    "        # Open the file and keep it open\n",
    "        self.file = open(self.csv_file, 'r')\n",
    "        \n",
    "        # Create an index of line offsets for random access\n",
    "        with open(self.csv_file, 'rb') as f:\n",
    "            mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)\n",
    "            self.line_offsets.append(0)\n",
    "            while mm.readline():\n",
    "                self.line_offsets.append(mm.tell())\n",
    "            mm.close()\n",
    "\n",
    "        # Remove the last offset (empty line at the end of file)\n",
    "        self.line_offsets.pop()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.line_offsets) - 1  # Subtract 1 to account for header\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Add 1 to idx to skip the header\n",
    "        self.file.seek(self.line_offsets[idx + 1])\n",
    "        line = self.file.readline().strip()\n",
    "\n",
    "        # Parse the CSV line\n",
    "        row = next(csv.reader([line]))\n",
    "        context, next_move, is_checkmate, outcome = row\n",
    "\n",
    "        context = context.split() if context else []\n",
    "        is_checkmate = float(is_checkmate)\n",
    "\n",
    "        # Tokenize input (context)\n",
    "        input_ids = self.tokenizer.encode(context)\n",
    "        input_ids = input_ids[-self.max_length:]  # Keep only the last max_length tokens\n",
    "        input_ids = [0] * (self.max_length - len(input_ids)) + input_ids  # Pad from the left\n",
    "\n",
    "        # Create labels (next_move)\n",
    "        labels = self.tokenizer.encode([next_move])[0]\n",
    "        \n",
    "        # Convert outcome to one-hot encoding (as float)\n",
    "        outcome_label = torch.zeros(3, dtype=torch.float)\n",
    "        if outcome == '1-0':\n",
    "            outcome_label[0] = 1.0\n",
    "        elif outcome == '0-1':\n",
    "            outcome_label[1] = 1.0\n",
    "        elif outcome == '1/2-1/2':\n",
    "            outcome_label[2] = 1.0\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long),\n",
    "            'is_checkmate': torch.tensor(is_checkmate, dtype=torch.float),\n",
    "            'outcome': outcome_label\n",
    "        }\n",
    "\n",
    "    def __del__(self):\n",
    "        # Close the file when the dataset object is destroyed\n",
    "        if hasattr(self, 'file'):\n",
    "            self.file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48e4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "def fit_tokenizer(csv_file):\n",
    "    unique_moves = set()\n",
    "    with open(csv_file, 'r') as data:\n",
    "        for row in data:\n",
    "            context, _next_move, _is_checkmate, _outcome = row.split(',')\n",
    "            context = context.strip().split()\n",
    "            for move in context:\n",
    "                unique_moves.add(move)\n",
    "        \n",
    "    tokenizer = ChessTokenizer()\n",
    "    tokenizer.fit(list(unique_moves))\n",
    "    return tokenizer\n",
    "\n",
    "def train_model(model, train_dataloader, val_dataloader, num_epochs, learning_rate, device):\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    move_criterion = nn.CrossEntropyLoss()\n",
    "    checkmate_criterion = nn.BCEWithLogitsLoss()\n",
    "    outcome_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    total_steps = num_epochs * len(train_dataloader)\n",
    "    progress_bar = tqdm(total=total_steps, desc=\"Training Progress\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch in train_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            move_labels = batch['labels'].to(device)\n",
    "            checkmate_labels = batch['is_checkmate'].to(device)\n",
    "            outcome_labels = batch['outcome'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            move_logits, checkmate_logits, outcome_logits = model(input_ids)\n",
    "\n",
    "            move_loss = move_criterion(move_logits, move_labels)\n",
    "            checkmate_loss = checkmate_criterion(checkmate_logits.squeeze(), checkmate_labels)\n",
    "            outcome_loss = outcome_criterion(outcome_logits, outcome_labels)\n",
    "\n",
    "            loss = move_loss + 0.1 * checkmate_loss + 0.1 * outcome_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.update(1)\n",
    "            progress_bar.set_postfix({'epoch': epoch+1, 'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                move_labels = batch['labels'].to(device)\n",
    "                checkmate_labels = batch['is_checkmate'].to(device)\n",
    "                outcome_labels = batch['outcome'].to(device)\n",
    "\n",
    "                move_logits, checkmate_logits, outcome_logits = model(input_ids)\n",
    "\n",
    "                move_loss = move_criterion(move_logits, move_labels)\n",
    "                checkmate_loss = checkmate_criterion(checkmate_logits.squeeze(), checkmate_labels)\n",
    "                outcome_loss = outcome_criterion(outcome_logits, outcome_labels)\n",
    "\n",
    "                loss = move_loss + 0.1 * checkmate_loss + 0.1 * outcome_loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}, Train Loss: {avg_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    progress_bar.close()\n",
    "    return model\n",
    "\n",
    "\n",
    "def calculate_random_baseline(dataloader, vocab_size, device):\n",
    "    total_loss = 0\n",
    "    move_criterion = nn.CrossEntropyLoss()\n",
    "    checkmate_criterion = nn.BCEWithLogitsLoss()\n",
    "    outcome_criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Calculating random baseline\"):\n",
    "        batch_size = batch['labels'].size(0)\n",
    "        \n",
    "        random_move_logits = torch.rand(batch_size, vocab_size).to(device)\n",
    "        random_checkmate_logits = torch.rand(batch_size, 1).to(device)\n",
    "        random_outcome_logits = torch.rand(batch_size, 3).to(device)\n",
    "\n",
    "        move_loss = move_criterion(random_move_logits, batch['labels'].to(device))\n",
    "        checkmate_loss = checkmate_criterion(random_checkmate_logits.squeeze(), batch['is_checkmate'].to(device))\n",
    "        outcome_loss = outcome_criterion(random_outcome_logits, batch['outcome'].to(device))\n",
    "\n",
    "        loss = move_loss + 0.1 * checkmate_loss + 0.1 * outcome_loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8da186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "print(f'Using device {get_device()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc50ce-908a-4a56-85e3-8606dede4024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer and model\n",
    "print(\"Initializing tokenizer...\")\n",
    "tokenizer = fit_tokenizer('out/training-data.csv')\n",
    "print(f'Tokenizer initialized with vocab_size={tokenizer.vocab_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d97f9be-8a52-441c-aa83-421156c4bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=16\n",
    "\n",
    "model = ChessTransformer(vocab_size=tokenizer.vocab_size, n_positions=MAX_LEN, n_embd=64, n_layer=4, n_head=4)\n",
    "# model = ChessTransformer(vocab_size=tokenizer.vocab_size, n_positions=MAX_LEN) # use defaults for small model\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"Loading training/validation data...\")\n",
    "train_dataset = ChessDataset('out/training-data.csv', tokenizer, max_length=MAX_LEN)\n",
    "val_dataset = ChessDataset('out/validation-data.csv', tokenizer, max_length=MAX_LEN)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256)\n",
    "\n",
    "# Get the appropriate device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Calculate random baseline loss\n",
    "random_baseline_loss = calculate_random_baseline(train_dataloader, model.config.vocab_size, device)\n",
    "print(f\"Random Baseline Loss: {random_baseline_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5337f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trained_model = train_model(model, train_dataloader, val_dataloader, num_epochs=5, learning_rate=5e-3, device=device)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(trained_model.state_dict(), 'chess_transformer_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac76c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def preprocess_input(move_sequence, tokenizer, max_length=25):\n",
    "    # Tokenize the input sequence\n",
    "    input_ids = tokenizer.encode(move_sequence)\n",
    "    \n",
    "    # Truncate or pad the sequence to max_length\n",
    "    if len(input_ids) > max_length:\n",
    "        input_ids = input_ids[-max_length:]\n",
    "    else:\n",
    "        input_ids = [0] * (max_length - len(input_ids)) + input_ids\n",
    "    \n",
    "    return torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "def predict_next_move(model, tokenizer, move_sequence, device, temperature=1.0, top_k=5):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    # Preprocess the input\n",
    "    input_ids = preprocess_input(move_sequence, tokenizer).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        move_logits, checkmate_logits, outcome_logits = model(input_ids)\n",
    "    \n",
    "    # Apply temperature to logits\n",
    "    move_logits = move_logits / temperature\n",
    "    \n",
    "    # Get probabilities\n",
    "    move_probs = F.softmax(move_logits, dim=-1)\n",
    "    \n",
    "    # Zero out the probability of the last move in the sequence\n",
    "    last_move_id = tokenizer.encode([move_sequence[-1]])[0]\n",
    "    move_probs[0, last_move_id] = 0\n",
    "    \n",
    "    # Normalize probabilities after zeroing out the last move\n",
    "    move_probs = move_probs / move_probs.sum()\n",
    "    \n",
    "    # Get top-k moves\n",
    "    top_k_probs, top_k_indices = torch.topk(move_probs, top_k)\n",
    "    \n",
    "    # Sample from top-k moves\n",
    "    sampled_index = torch.multinomial(top_k_probs.squeeze(), 1).item()\n",
    "    predicted_move_id = top_k_indices.squeeze()[sampled_index].item()\n",
    "    predicted_move = tokenizer.decode([predicted_move_id])\n",
    "    \n",
    "    # Get the checkmate probability\n",
    "    checkmate_prob = torch.sigmoid(checkmate_logits).item()\n",
    "    \n",
    "    # Get the game outcome probabilities\n",
    "    outcome_probs = F.softmax(outcome_logits, dim=-1).squeeze()\n",
    "    \n",
    "    return predicted_move, checkmate_prob, outcome_probs, move_probs\n",
    "\n",
    "def interpret_prediction(predicted_move, checkmate_prob, outcome_probs, move_probs, tokenizer):\n",
    "    outcomes = ['Win', 'Loss', 'Draw']\n",
    "    outcome_dict = {outcome: prob.item() for outcome, prob in zip(outcomes, outcome_probs)}\n",
    "    most_likely_outcome = max(outcome_dict, key=outcome_dict.get)\n",
    "    \n",
    "    print(f\"Predicted next move: {predicted_move}\")\n",
    "    print(f\"Checkmate probability: {checkmate_prob:.2f}\")\n",
    "    print(\"Game outcome probabilities:\")\n",
    "    for outcome, prob in outcome_dict.items():\n",
    "        print(f\"  {outcome}: {prob:.2f}\")\n",
    "    print(f\"Most likely outcome: {most_likely_outcome}\")\n",
    "    \n",
    "    # Debugging information\n",
    "    print(\"\\nDebugging Information:\")\n",
    "    print(f\"Vocabulary size: {len(tokenizer.move_to_id)}\")\n",
    "    print(\"Top 5 predicted moves:\")\n",
    "    top_moves = torch.topk(move_probs.squeeze(), 5)\n",
    "    for i, (prob, idx) in enumerate(zip(top_moves.values, top_moves.indices)):\n",
    "        move = tokenizer.decode([idx.item()])\n",
    "        print(f\"  {i+1}. {move} (probability: {prob.item():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "168d33de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_tokenizer\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout/training-data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTokenizer initialized with vocab_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer\u001b[38;5;241m.\u001b[39mvocab_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m ChessTransformer(vocab_size\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mvocab_size, n_positions\u001b[38;5;241m=\u001b[39mMAX_LEN, n_embd\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m) \u001b[38;5;66;03m# use defaults for small model\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fit_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = fit_tokenizer('out/training-data.csv')\n",
    "print(f'Tokenizer initialized with vocab_size={tokenizer.vocab_size}')\n",
    "model = ChessTransformer(vocab_size=tokenizer.vocab_size, n_positions=MAX_LEN, n_embd=64) # use defaults for small model\n",
    "model.load_state_dict(torch.load('chess_transformer_model.pth'))\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aaa768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example move sequence\n",
    "move_sequence = [\"e4\", \"c6\", \"d4\", \"e5\", \"d5\", \"e5\"]\n",
    "\n",
    "# Make multiple predictions\n",
    "for _ in range(5):\n",
    "    predicted_move, checkmate_prob, outcome_probs, move_probs = predict_next_move(model, tokenizer, move_sequence, device, temperature=0.8, top_k=5)\n",
    "    print(\"\\n--- New Prediction ---\")\n",
    "    interpret_prediction(predicted_move, checkmate_prob, outcome_probs, move_probs, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815935d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
